{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "disciplinary-relevance",
      "metadata": {
        "id": "disciplinary-relevance"
      },
      "source": [
        "# Classification - Women's E-Commerce Clothing Reviews"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsTNaD1Yk7DO",
        "outputId": "310fb65c-1157-4430-c6ef-79ed7dab815e"
      },
      "id": "LsTNaD1Yk7DO",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz\n",
        "!tar -xvf spark-2.4.0-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.0-bin-hadoop2.7\"\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQD1FOPwk98I",
        "outputId": "2bb0a5f3-e64f-4f42-9d6b-7746f80da899"
      },
      "id": "fQD1FOPwk98I",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spark-2.4.0-bin-hadoop2.7/\n",
            "spark-2.4.0-bin-hadoop2.7/python/\n",
            "spark-2.4.0-bin-hadoop2.7/python/setup.cfg\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/resultiterable.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/python/\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/python/pyspark/\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/python/pyspark/shell.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/heapq3.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/join.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/version.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/rdd.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/java_gateway.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/find_spark_home.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/_globals.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/worker.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/feature.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/random.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/recommendation.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/fpm.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/stat/\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/stat/KernelDensity.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/stat/distribution.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/stat/test.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/stat/_statistics.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/stat/__init__.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/util.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/clustering.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/linalg/\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/linalg/distributed.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/linalg/__init__.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/tree.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/__init__.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/evaluation.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/tests.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/util.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/test_broadcast.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/shell.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/feature.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/recommendation.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/fpm.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/classification.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/stat.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/util.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/tuning.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/regression.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/base.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/clustering.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/wrapper.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/pipeline.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/linalg/\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/linalg/__init__.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/param/\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/param/_shared_params_code_gen.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/param/shared.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/param/__init__.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/__init__.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/evaluation.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/common.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/tests.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/image.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/test_serializers.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/cloudpickle.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/daemon.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/files.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/rddsampler.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/statcounter.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/kafka.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/util.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/kinesis.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/flume.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/__init__.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/context.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/tests.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/dstream.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/listener.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/taskcontext.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/__init__.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/storagelevel.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/broadcast.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/profiler.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/traceback_utils.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/context.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/status.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/streaming.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/readwriter.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/catalog.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/session.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/column.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/functions.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/dataframe.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/window.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/udf.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/__init__.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/group.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/context.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/tests.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/conf.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/types.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/tests.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/conf.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark/shuffle.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/.gitignore\n",
            "spark-2.4.0-bin-hadoop2.7/python/docs/\n",
            "spark-2.4.0-bin-hadoop2.7/python/docs/epytext.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/docs/make2.bat\n",
            "spark-2.4.0-bin-hadoop2.7/python/docs/pyspark.sql.rst\n",
            "spark-2.4.0-bin-hadoop2.7/python/docs/make.bat\n",
            "spark-2.4.0-bin-hadoop2.7/python/docs/index.rst\n",
            "spark-2.4.0-bin-hadoop2.7/python/docs/_templates/\n",
            "spark-2.4.0-bin-hadoop2.7/python/docs/_templates/layout.html\n",
            "spark-2.4.0-bin-hadoop2.7/python/docs/_static/\n",
            "spark-2.4.0-bin-hadoop2.7/python/docs/_static/pyspark.js\n",
            "spark-2.4.0-bin-hadoop2.7/python/docs/_static/pyspark.css\n",
            "spark-2.4.0-bin-hadoop2.7/python/docs/pyspark.ml.rst\n",
            "spark-2.4.0-bin-hadoop2.7/python/docs/pyspark.streaming.rst\n",
            "spark-2.4.0-bin-hadoop2.7/python/docs/conf.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/docs/pyspark.mllib.rst\n",
            "spark-2.4.0-bin-hadoop2.7/python/docs/pyspark.rst\n",
            "spark-2.4.0-bin-hadoop2.7/python/docs/Makefile\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_coverage/\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_coverage/conf/\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_coverage/conf/spark-defaults.conf\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_coverage/sitecustomize.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_coverage/coverage_daemon.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/run-tests-with-coverage\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark.egg-info/\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark.egg-info/top_level.txt\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark.egg-info/dependency_links.txt\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark.egg-info/requires.txt\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark.egg-info/PKG-INFO\n",
            "spark-2.4.0-bin-hadoop2.7/python/pyspark.egg-info/SOURCES.txt\n",
            "spark-2.4.0-bin-hadoop2.7/python/MANIFEST.in\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/userlibrary.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/userlib-0.1.zip\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/SimpleHTTPServer.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/hello/\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/hello/sub_hello/\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/hello/sub_hello/sub_hello.txt\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/hello/hello.txt\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/people_array.json\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/text-test.txt\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/ages_newlines.csv\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/people.json\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_common_metadata\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_metadata\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_SUCCESS\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/streaming/\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/streaming/text-test.txt\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/ages.csv\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/people1.json\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/_SUCCESS\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-2.4.0-bin-hadoop2.7/python/test_support/sql/people_array_utf16le.json\n",
            "spark-2.4.0-bin-hadoop2.7/python/run-tests.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/run-tests\n",
            "spark-2.4.0-bin-hadoop2.7/python/.coveragerc\n",
            "spark-2.4.0-bin-hadoop2.7/python/lib/\n",
            "spark-2.4.0-bin-hadoop2.7/python/lib/pyspark.zip\n",
            "spark-2.4.0-bin-hadoop2.7/python/lib/PY4J_LICENSE.txt\n",
            "spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip\n",
            "spark-2.4.0-bin-hadoop2.7/python/setup.py\n",
            "spark-2.4.0-bin-hadoop2.7/python/README.md\n",
            "spark-2.4.0-bin-hadoop2.7/python/dist/\n",
            "spark-2.4.0-bin-hadoop2.7/python/pylintrc\n",
            "spark-2.4.0-bin-hadoop2.7/conf/\n",
            "spark-2.4.0-bin-hadoop2.7/conf/fairscheduler.xml.template\n",
            "spark-2.4.0-bin-hadoop2.7/conf/spark-defaults.conf.template\n",
            "spark-2.4.0-bin-hadoop2.7/conf/docker.properties.template\n",
            "spark-2.4.0-bin-hadoop2.7/conf/log4j.properties.template\n",
            "spark-2.4.0-bin-hadoop2.7/conf/metrics.properties.template\n",
            "spark-2.4.0-bin-hadoop2.7/conf/slaves.template\n",
            "spark-2.4.0-bin-hadoop2.7/conf/spark-env.sh.template\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-heapq.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-paranamer.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-graphlib-dot.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-minlog.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-slf4j.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-jquery.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-scopt.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-vis.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-sbt-launch-lib.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-spire.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-matchMedia-polyfill.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-kryo.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-arpack.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-scala.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-javassist.html\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-json-formatter.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-jodd.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-automaton.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-janino.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-dagre-d3.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-sorttable.js.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-py4j.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-d3.min.js.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-respond.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-CC0.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-zstd.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-cloudpickle.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-pmml-model.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-pyrolite.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-netlib.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-AnchorJS.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-modernizr.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-machinist.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-javolution.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-xmlenc.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-join.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-jline.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-antlr.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-jtransforms.html\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-leveldbjni.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-protobuf.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-bootstrap.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-zstd-jni.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-datatables.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-f2j.txt\n",
            "spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-reflectasm.txt\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/start-slave.sh\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/stop-history-server.sh\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/stop-slave.sh\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/stop-mesos-dispatcher.sh\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/start-all.sh\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/spark-daemon.sh\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/start-master.sh\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/spark-daemons.sh\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/spark-config.sh\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/start-slaves.sh\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/start-mesos-shuffle-service.sh\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/start-history-server.sh\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/start-shuffle-service.sh\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/slaves.sh\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/stop-slaves.sh\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/stop-thriftserver.sh\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/stop-master.sh\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/stop-shuffle-service.sh\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/start-mesos-dispatcher.sh\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/stop-mesos-shuffle-service.sh\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/start-thriftserver.sh\n",
            "spark-2.4.0-bin-hadoop2.7/sbin/stop-all.sh\n",
            "spark-2.4.0-bin-hadoop2.7/kubernetes/\n",
            "spark-2.4.0-bin-hadoop2.7/kubernetes/tests/\n",
            "spark-2.4.0-bin-hadoop2.7/kubernetes/tests/pyfiles.py\n",
            "spark-2.4.0-bin-hadoop2.7/kubernetes/tests/worker_memory_check.py\n",
            "spark-2.4.0-bin-hadoop2.7/kubernetes/tests/py_container_checks.py\n",
            "spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/\n",
            "spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/\n",
            "spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/Dockerfile\n",
            "spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/\n",
            "spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/\n",
            "spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
            "spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/\n",
            "spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
            "spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/entrypoint.sh\n",
            "spark-2.4.0-bin-hadoop2.7/jars/\n",
            "spark-2.4.0-bin-hadoop2.7/jars/commons-lang3-3.5.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/arrow-format-0.10.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hadoop-yarn-common-2.7.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-jobclient-2.7.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/json4s-jackson_2.11-3.5.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jersey-container-servlet-2.22.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/curator-framework-2.7.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/parquet-column-1.10.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/pyrolite-4.13.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/bonecp-0.8.0.RELEASE.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hppc-0.7.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/metrics-jvm-3.1.5.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jersey-guava-2.22.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/guice-3.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/super-csv-2.2.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jsp-api-2.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/commons-net-3.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/validation-api-1.1.0.Final.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/json4s-ast_2.11-3.5.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/javax.inject-1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-shuffle-2.7.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/avro-ipc-1.8.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spark-network-shuffle_2.11-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/orc-shims-1.5.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jersey-container-servlet-core-2.22.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/zjsonpatch-0.3.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/scala-compiler-2.11.12.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spark-graphx_2.11-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/curator-client-2.7.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jersey-media-jaxb-2.22.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/avro-mapred-1.8.2-hadoop2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/antlr4-runtime-4.7.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spark-kubernetes_2.11-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jackson-module-jaxb-annotations-2.6.7.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/okhttp-3.8.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/leveldbjni-all-1.8.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spark-tags_2.11-2.4.0-tests.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jackson-mapper-asl-1.9.13.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/ST4-4.0.4.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/eigenbase-properties-1.1.5.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jackson-jaxrs-1.9.13.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/commons-beanutils-1.7.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jackson-annotations-2.6.7.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/kubernetes-model-2.0.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spark-tags_2.11-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jackson-module-paranamer-2.7.9.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jdo-api-3.0.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jersey-server-2.22.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/scala-parser-combinators_2.11-1.1.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/snappy-java-1.1.7.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/arrow-memory-0.10.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hk2-utils-2.4.0-b34.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spark-repl_2.11-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/joda-time-2.9.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/commons-crypto-1.0.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/aopalliance-1.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/log4j-1.2.17.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/commons-pool-1.5.4.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/xz-1.5.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hk2-locator-2.4.0-b34.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/libthrift-0.9.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/chill-java-0.9.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/logging-interceptor-3.8.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/opencsv-2.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/lz4-java-1.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spark-streaming_2.11-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/slf4j-log4j12-1.7.16.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/calcite-core-1.2.0-incubating.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/breeze_2.11-0.13.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/parquet-hadoop-bundle-1.6.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spark-hive-thriftserver_2.11-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/javax.inject-2.4.0-b34.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/metrics-json-3.1.5.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/aopalliance-repackaged-2.4.0-b34.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spark-mesos_2.11-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jcl-over-slf4j-1.7.16.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/antlr-runtime-3.4.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/httpcore-4.4.10.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/metrics-graphite-3.1.5.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/netty-3.9.9.Final.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/guava-14.0.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jaxb-api-2.2.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/datanucleus-core-3.2.10.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/compress-lzf-1.0.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/antlr-2.7.7.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jersey-common-2.22.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hadoop-yarn-client-2.7.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/commons-lang-2.6.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/datanucleus-api-jdo-3.2.6.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/commons-digester-1.8.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hadoop-annotations-2.7.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jtransforms-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jodd-core-3.5.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/snakeyaml-1.15.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/commons-cli-1.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/parquet-format-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/commons-configuration-1.6.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jpam-1.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/kryo-shaded-4.0.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/zookeeper-3.4.6.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/javax.ws.rs-api-2.0.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jackson-core-asl-1.9.13.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-core-2.7.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/json4s-scalap_2.11-3.5.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spark-kvstore_2.11-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/avro-1.8.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hadoop-yarn-api-2.7.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/api-asn1-api-1.0.0-M20.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/paranamer-2.8.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/RoaringBitmap-0.5.11.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/janino-3.0.9.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/stringtemplate-3.2.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/apacheds-i18n-2.0.0-M15.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/apache-log4j-extras-1.2.17.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/xbean-asm6-shaded-4.8.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/curator-recipes-2.7.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/oro-2.0.8.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/javax.annotation-api-1.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/chill_2.11-0.9.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spark-mllib_2.11-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hive-exec-1.2.1.spark2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/commons-dbcp-1.4.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/mesos-1.4.0-shaded-protobuf.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spark-core_2.11-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/okio-1.13.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jackson-databind-2.6.7.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/netty-all-4.1.17.Final.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/commons-compiler-3.0.9.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/parquet-hadoop-1.10.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/commons-math3-3.4.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/httpclient-4.5.6.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jul-to-slf4j-1.7.16.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/stax-api-1.0-2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/core-1.1.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/commons-codec-1.10.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/gson-2.2.4.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/zstd-jni-1.3.2-2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/javolution-5.5.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/univocity-parsers-2.7.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/apacheds-kerberos-codec-2.0.0-M15.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/kubernetes-client-3.0.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/parquet-common-1.10.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hadoop-yarn-server-common-2.7.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/libfb303-0.9.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/orc-mapreduce-1.5.2-nohive.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jersey-client-2.22.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/xercesImpl-2.9.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/commons-collections-3.2.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/machinist_2.11-0.6.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/htrace-core-3.1.0-incubating.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jta-1.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/osgi-resource-locator-1.0.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/datanucleus-rdbms-3.2.9.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spark-unsafe_2.11-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/javassist-3.18.1-GA.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spire-macros_2.11-0.13.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/calcite-linq4j-1.2.0-incubating.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jline-2.14.6.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spark-launcher_2.11-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hadoop-client-2.7.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hive-metastore-1.2.1.spark2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hadoop-yarn-server-web-proxy-2.7.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spire_2.11-0.13.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jackson-core-2.6.7.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/api-util-1.0.0-M20.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/commons-httpclient-3.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/orc-core-1.5.2-nohive.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/aircompressor-0.10.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/guice-servlet-3.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/scala-xml_2.11-1.0.5.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-common-2.7.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spark-hive_2.11-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/protobuf-java-2.5.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/parquet-jackson-1.10.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spark-sketch_2.11-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hive-beeline-1.2.1.spark2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spark-network-common_2.11-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/commons-beanutils-core-1.8.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/stream-2.7.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/commons-compress-1.8.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/macro-compat_2.11-1.1.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/activation-1.1.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/breeze-macros_2.11-0.13.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/derby-10.12.1.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/shapeless_2.11-2.3.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/minlog-1.3.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/commons-logging-1.1.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spark-sql_2.11-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spark-mllib-local_2.11-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hive-cli-1.2.1.spark2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/metrics-core-3.1.5.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jackson-module-scala_2.11-2.6.7.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/automaton-1.11-8.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/objenesis-2.5.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/json4s-core_2.11-3.5.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/py4j-0.10.7.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jetty-6.1.26.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/slf4j-api-1.7.16.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/commons-io-2.4.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jackson-xc-1.9.13.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/scala-reflect-2.11.12.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/xmlenc-0.52.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/spark-yarn_2.11-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jetty-util-6.1.26.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/ivy-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/scala-library-2.11.12.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/snappy-0.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jsr305-1.3.9.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/arpack_combined_all-0.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/stax-api-1.0.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-app-2.7.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hk2-api-2.4.0-b34.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/jackson-dataformat-yaml-2.6.7.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/arrow-vector-0.10.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/flatbuffers-1.2.0-3f79e055.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/calcite-avatica-1.2.0-incubating.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/generex-1.0.1.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/JavaEWAH-0.3.2.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/parquet-encoding-1.10.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/javax.servlet-api-3.1.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hadoop-hdfs-2.7.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/jars/hadoop-auth-2.7.3.jar\n",
            "spark-2.4.0-bin-hadoop2.7/bin/\n",
            "spark-2.4.0-bin-hadoop2.7/bin/beeline\n",
            "spark-2.4.0-bin-hadoop2.7/bin/pyspark\n",
            "spark-2.4.0-bin-hadoop2.7/bin/pyspark.cmd\n",
            "spark-2.4.0-bin-hadoop2.7/bin/find-spark-home\n",
            "spark-2.4.0-bin-hadoop2.7/bin/spark-submit2.cmd\n",
            "spark-2.4.0-bin-hadoop2.7/bin/spark-class.cmd\n",
            "spark-2.4.0-bin-hadoop2.7/bin/run-example\n",
            "spark-2.4.0-bin-hadoop2.7/bin/sparkR2.cmd\n",
            "spark-2.4.0-bin-hadoop2.7/bin/spark-sql2.cmd\n",
            "spark-2.4.0-bin-hadoop2.7/bin/spark-submit.cmd\n",
            "spark-2.4.0-bin-hadoop2.7/bin/run-example.cmd\n",
            "spark-2.4.0-bin-hadoop2.7/bin/sparkR.cmd\n",
            "spark-2.4.0-bin-hadoop2.7/bin/spark-class2.cmd\n",
            "spark-2.4.0-bin-hadoop2.7/bin/spark-submit\n",
            "spark-2.4.0-bin-hadoop2.7/bin/sparkR\n",
            "spark-2.4.0-bin-hadoop2.7/bin/spark-sql.cmd\n",
            "spark-2.4.0-bin-hadoop2.7/bin/load-spark-env.cmd\n",
            "spark-2.4.0-bin-hadoop2.7/bin/pyspark2.cmd\n",
            "spark-2.4.0-bin-hadoop2.7/bin/docker-image-tool.sh\n",
            "spark-2.4.0-bin-hadoop2.7/bin/spark-shell\n",
            "spark-2.4.0-bin-hadoop2.7/bin/find-spark-home.cmd\n",
            "spark-2.4.0-bin-hadoop2.7/bin/spark-shell.cmd\n",
            "spark-2.4.0-bin-hadoop2.7/bin/load-spark-env.sh\n",
            "spark-2.4.0-bin-hadoop2.7/bin/spark-sql\n",
            "spark-2.4.0-bin-hadoop2.7/bin/spark-shell2.cmd\n",
            "spark-2.4.0-bin-hadoop2.7/bin/spark-class\n",
            "spark-2.4.0-bin-hadoop2.7/bin/beeline.cmd\n",
            "spark-2.4.0-bin-hadoop2.7/RELEASE\n",
            "spark-2.4.0-bin-hadoop2.7/R/\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/NAMESPACE\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/doc/\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/doc/sparkr-vignettes.Rmd\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/doc/sparkr-vignettes.html\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/doc/sparkr-vignettes.R\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/doc/index.html\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/DESCRIPTION\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/R/\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdb\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/R/SparkR\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdx\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/html/\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/html/R.css\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/html/00Index.html\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/help/\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/help/AnIndex\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdb\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/help/aliases.rds\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdx\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/help/paths.rds\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/profile/\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/profile/general.R\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/profile/shell.R\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/tests/\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/tests/testthat/\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/tests/testthat/test_basic.R\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/vignette.rds\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/package.rds\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/Rd.rds\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/nsInfo.rds\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/hsearch.rds\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/features.rds\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/links.rds\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/worker/\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/worker/daemon.R\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/worker/worker.R\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/INDEX\n",
            "spark-2.4.0-bin-hadoop2.7/R/lib/sparkr.zip\n",
            "spark-2.4.0-bin-hadoop2.7/yarn/\n",
            "spark-2.4.0-bin-hadoop2.7/yarn/spark-2.4.0-yarn-shuffle.jar\n",
            "spark-2.4.0-bin-hadoop2.7/examples/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/jars/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/jars/spark-examples_2.11-2.4.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/examples/jars/scopt_2.11-3.7.0.jar\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/als.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/pagerank.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/ranking_metrics_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/tf_idf_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/k_means_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_regression_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_classification_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/elementwise_product_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/stratified_sampling_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/fpgrowth_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/sampled_rdds.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/streaming_k_means_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/correlations.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/correlations_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/regression_metrics_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/naive_bayes_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/word2vec.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/recommendation_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/random_rdd_generation.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/summary_statistics_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/word2vec_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/kmeans.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/standard_scaler_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/svd_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/normalizer_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/isotonic_regression_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/parquet_inputformat.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/logistic_regression.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/rformula_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/min_max_scaler_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/min_hash_lsh_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_classification_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/tf_idf_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_regression_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/vector_slicer_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/als_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/cross_validator.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/onehot_encoder_estimator_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/random_forest_regressor_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/chisq_selector_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/max_abs_scaler_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/n_gram_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/elementwise_product_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/binarizer_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/imputer_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/correlation_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/count_vectorizer_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/stopwords_remover_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/fpgrowth_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/kmeans_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/chi_square_test_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/aft_survival_regression.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/dct_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/dataframe_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/pca_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/pipeline_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/polynomial_expansion_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/tokenizer_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/naive_bayes_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/string_indexer_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/summarizer_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/bucketizer_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/vector_assembler_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/sql_transformer.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/feature_hasher_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/vector_indexer_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/train_validation_split.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/vector_size_hint_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/one_vs_rest_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/bisecting_k_means_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/index_to_string_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/linearsvc.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/word2vec_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/standard_scaler_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/prefixspan_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/lda_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/normalizer_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/quantile_discretizer_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/random_forest_classifier_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/isotonic_regression_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/gaussian_mixture_example.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/transitive_closure.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/flume_wordcount.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/queue_stream.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/kafka_wordcount.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/hdfs_wordcount.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/direct_kafka_wordcount.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/network_wordcount.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/sql_network_wordcount.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/wordcount.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/status_api_demo.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/basic.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/arrow.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/datasource.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/hive.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/kmeans.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sort.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/pi.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/python/avro_inputformat.py\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LinearRegression.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RegressionMetricsExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LinearRegressionWithSGDExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderEstimatorExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRegressionMetricsExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLinearRegressionWithSGDExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderEstimatorExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/RSparkSQLExample.R\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/glm.R\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/als.R\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/kmeans.R\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/mlp.R\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/lda.R\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/ml.R\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/naiveBayes.R\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/kstest.R\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/gbt.R\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/survreg.R\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/svmLinear.R\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/bisectingKmeans.R\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/gaussianMixture.R\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/isoreg.R\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/randomForest.R\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/decisionTree.R\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/logit.R\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/fpm.R\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/data-manipulation.R\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/streaming/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/streaming/structured_network_wordcount.R\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/r/dataframe.R\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/people.csv\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/users.avro\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/employees.json\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/full_user.avsc\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/people.json\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/people.txt\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/kv1.txt\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/users.parquet\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/users.orc\n",
            "spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/user.avsc\n",
            "spark-2.4.0-bin-hadoop2.7/NOTICE\n",
            "spark-2.4.0-bin-hadoop2.7/data/\n",
            "spark-2.4.0-bin-hadoop2.7/data/graphx/\n",
            "spark-2.4.0-bin-hadoop2.7/data/graphx/users.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/graphx/followers.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/gmm_data.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA.png\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/kittens/\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/kittens/DP153539.jpg\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/kittens/54893.jpg\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/kittens/not-image.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/kittens/DP802813.jpg\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/license.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/license.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/chr30.4.184.jpg\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/grayscale.jpg\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA_alpha_60.png\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA.png\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP153539.jpg\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/54893.jpg\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP802813.jpg\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/not-image.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/29.5.a_b_EGDP022204.jpg\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/sample_linear_regression_data.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/sample_lda_data.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/kmeans_data.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/sample_svm_data.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/streaming_kmeans_data_test.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/sample_kmeans_data.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/sample_multiclass_classification_data.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/sample_fpgrowth.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/pic_data.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/pagerank_data.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/als/\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/als/test.data\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/als/sample_movielens_ratings.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/sample_lda_libsvm_data.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/sample_binary_classification_data.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/ridge-data/\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/ridge-data/lpsa.data\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/sample_movielens_data.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/iris_libsvm.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt\n",
            "spark-2.4.0-bin-hadoop2.7/data/streaming/\n",
            "spark-2.4.0-bin-hadoop2.7/data/streaming/AFINN-111.txt\n",
            "spark-2.4.0-bin-hadoop2.7/README.md\n",
            "spark-2.4.0-bin-hadoop2.7/LICENSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90fCXbEclE-U",
        "outputId": "0bf287d5-0686-4368-a88d-b4463056616c"
      },
      "id": "90fCXbEclE-U",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/gdrive/My Drive/Colab Notebooks/LDS9/thi/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1Aegba5lJGl",
        "outputId": "50b4f202-fb69-4cf0-e45b-dd2003509882"
      },
      "id": "F1Aegba5lJGl",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/LDS9/thi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "amber-establishment",
      "metadata": {
        "id": "amber-establishment"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "guilty-attendance",
      "metadata": {
        "id": "guilty-attendance"
      },
      "outputs": [],
      "source": [
        "import pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "detailed-henry",
      "metadata": {
        "id": "detailed-henry"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.conf import SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "smart-reporter",
      "metadata": {
        "id": "smart-reporter"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SQLContext "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "comfortable-listing",
      "metadata": {
        "id": "comfortable-listing"
      },
      "outputs": [],
      "source": [
        "sc = SparkContext(master = \"local\", appName= \"Ex1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "found-commodity",
      "metadata": {
        "id": "found-commodity"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession(sc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acquired-radio",
      "metadata": {
        "id": "acquired-radio"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "liquid-journalist",
      "metadata": {
        "id": "liquid-journalist"
      },
      "outputs": [],
      "source": [
        "pdf = pd.read_excel('womens-ecommerce-clothing-reviews/Womens_Clothing_E_Commerce_Reviews.xlsx', \n",
        "                               sheet_name='Reviews', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "medieval-talent",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "medieval-talent",
        "outputId": "83b5ad51-ccd2-4b04-f078-ace53dcd5a13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f07cf714-face-4771-b0ac-291311fc382b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clothing ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>Department Name</th>\n",
              "      <th>Class Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>767</td>\n",
              "      <td>33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Initmates</td>\n",
              "      <td>Intimate</td>\n",
              "      <td>Intimates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1080</td>\n",
              "      <td>34</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1077</td>\n",
              "      <td>60</td>\n",
              "      <td>Some major design flaws</td>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1049</td>\n",
              "      <td>50</td>\n",
              "      <td>My favorite buy!</td>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Bottoms</td>\n",
              "      <td>Pants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>847</td>\n",
              "      <td>47</td>\n",
              "      <td>Flattering shirt</td>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Blouses</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f07cf714-face-4771-b0ac-291311fc382b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f07cf714-face-4771-b0ac-291311fc382b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f07cf714-face-4771-b0ac-291311fc382b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Clothing ID  Age  ... Department Name Class Name\n",
              "0          767   33  ...        Intimate  Intimates\n",
              "1         1080   34  ...         Dresses    Dresses\n",
              "2         1077   60  ...         Dresses    Dresses\n",
              "3         1049   50  ...         Bottoms      Pants\n",
              "4          847   47  ...            Tops    Blouses\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "pdf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "specified-bacon",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "specified-bacon",
        "outputId": "20e9e2f5-3697-4781-d1e7-41109d1142b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 23481 entries, 0 to 23480\n",
            "Data columns (total 10 columns):\n",
            " #   Column                   Non-Null Count  Dtype \n",
            "---  ------                   --------------  ----- \n",
            " 0   Clothing ID              23481 non-null  int64 \n",
            " 1   Age                      23481 non-null  int64 \n",
            " 2   Title                    19671 non-null  object\n",
            " 3   Review Text              22636 non-null  object\n",
            " 4   Rating                   23481 non-null  int64 \n",
            " 5   Recommended IND          23481 non-null  int64 \n",
            " 6   Positive Feedback Count  23481 non-null  int64 \n",
            " 7   Division Name            23467 non-null  object\n",
            " 8   Department Name          23467 non-null  object\n",
            " 9   Class Name               23467 non-null  object\n",
            "dtypes: int64(5), object(5)\n",
            "memory usage: 2.0+ MB\n"
          ]
        }
      ],
      "source": [
        "pdf.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "latin-bunch",
      "metadata": {
        "id": "latin-bunch"
      },
      "outputs": [],
      "source": [
        "pdf['Title'] = pdf['Title'].astype(str)\n",
        "pdf['Review Text'] = pdf['Review Text'].astype(str)\n",
        "pdf['Rating'] = pdf['Rating'].astype(int)\n",
        "pdf['Division Name'] = pdf['Division Name'].astype(str)\n",
        "pdf['Department Name'] = pdf['Department Name'].astype(str)\n",
        "pdf['Class Name'] = pdf['Class Name'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "narrow-lesbian",
      "metadata": {
        "id": "narrow-lesbian"
      },
      "outputs": [],
      "source": [
        "data = spark.createDataFrame(pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "unsigned-edition",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unsigned-edition",
        "outputId": "0b582ee8-2f7e-42e3-8545-fe011854dcbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---+--------------------+--------------------+------+---------------+-----------------------+--------------+---------------+----------+\n",
            "|Clothing ID|Age|               Title|         Review Text|Rating|Recommended IND|Positive Feedback Count| Division Name|Department Name|Class Name|\n",
            "+-----------+---+--------------------+--------------------+------+---------------+-----------------------+--------------+---------------+----------+\n",
            "|        767| 33|                 nan|Absolutely wonder...|     4|              1|                      0|     Initmates|       Intimate| Intimates|\n",
            "|       1080| 34|                 nan|Love this dress! ...|     5|              1|                      4|       General|        Dresses|   Dresses|\n",
            "|       1077| 60|Some major design...|I had such high h...|     3|              0|                      0|       General|        Dresses|   Dresses|\n",
            "|       1049| 50|    My favorite buy!|I love, love, lov...|     5|              1|                      0|General Petite|        Bottoms|     Pants|\n",
            "|        847| 47|    Flattering shirt|This shirt is ver...|     5|              1|                      6|       General|           Tops|   Blouses|\n",
            "+-----------+---+--------------------+--------------------+------+---------------+-----------------------+--------------+---------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "joint-yahoo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joint-yahoo",
        "outputId": "c06cea6f-2bba-43dc-9452-526609e0da3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Clothing ID: long (nullable = true)\n",
            " |-- Age: long (nullable = true)\n",
            " |-- Title: string (nullable = true)\n",
            " |-- Review Text: string (nullable = true)\n",
            " |-- Rating: long (nullable = true)\n",
            " |-- Recommended IND: long (nullable = true)\n",
            " |-- Positive Feedback Count: long (nullable = true)\n",
            " |-- Division Name: string (nullable = true)\n",
            " |-- Department Name: string (nullable = true)\n",
            " |-- Class Name: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "accessible-hindu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "accessible-hindu",
        "outputId": "b26e7c3d-f35e-44c1-d199-1d10ed082455"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Clothing ID',\n",
              " 'Age',\n",
              " 'Title',\n",
              " 'Review Text',\n",
              " 'Rating',\n",
              " 'Recommended IND',\n",
              " 'Positive Feedback Count',\n",
              " 'Division Name',\n",
              " 'Department Name',\n",
              " 'Class Name']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "psychological-engineering",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psychological-engineering",
        "outputId": "d23f96cf-c80d-4d28-c24d-fbb1ae748fd1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23481"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "data.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "spatial-mainland",
      "metadata": {
        "id": "spatial-mainland"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "modern-northeast",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "modern-northeast",
        "outputId": "d230132f-ef3f-4779-eaa2-24c6987c9e69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "data.filter(data['Title'].isNull()).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "imposed-understanding",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imposed-understanding",
        "outputId": "17c268a0-6379-487c-f246-20fdc7fe23b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "data.filter(data['Review Text'].isNull()).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "introductory-kernel",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "introductory-kernel",
        "outputId": "9849ce03-5557-4355-e0df-2d0228bd595c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "data.filter(data['Recommended IND'].isNull()).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "effective-catch",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "effective-catch",
        "outputId": "de29dc99-474f-4207-c612-bfa7fdb344a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "data.filter(data['Positive Feedback Count'].isNull()).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "informational-trader",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "informational-trader",
        "outputId": "4231f57e-2ef1-4c5f-f54e-f58d7ab2cf78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "data.filter(data['Rating'].isNull()).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "gross-jonathan",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gross-jonathan",
        "outputId": "b04058d1-4586-4f88-9857-93cb12f1095d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23481"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "data.dropna(how= 'any', subset=['Title', 'Review Text', 'Recommended IND', 'Positive Feedback Count', 'Rating']).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "utility-hormone",
      "metadata": {
        "id": "utility-hormone"
      },
      "outputs": [],
      "source": [
        "data = data.drop_duplicates()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "decimal-berry",
      "metadata": {
        "id": "decimal-berry"
      },
      "source": [
        "# Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "north-abraham",
      "metadata": {
        "id": "north-abraham"
      },
      "outputs": [],
      "source": [
        "#data_processed = data.select(['Review Text', 'Rating'])\n",
        "data_processed = data.select(['Title', 'Review Text', 'Recommended IND', 'Positive Feedback Count', 'Rating'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "latter-analyst",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "latter-analyst",
        "outputId": "87f30610-1d4b-404b-cd7b-448eb65853c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+---------------+-----------------------+------+\n",
            "|               Title|         Review Text|Recommended IND|Positive Feedback Count|Rating|\n",
            "+--------------------+--------------------+---------------+-----------------------+------+\n",
            "|                 nan|                 nan|              1|                      0|     5|\n",
            "|No slip and total...|I just received t...|              0|                      0|     2|\n",
            "|           A winner!|What a well-desig...|              1|                      6|     5|\n",
            "|                 nan|This top is full ...|              1|                      1|     5|\n",
            "|Darling top- runs...|I am a solid size...|              1|                      0|     4|\n",
            "| Perfect work pants!|I love these pant...|              1|                      0|     5|\n",
            "|Looks cute - but ...|This jacket looke...|              0|                      4|     2|\n",
            "|    Great fall dress|I tried this dres...|              1|                      0|     5|\n",
            "|Do not buy this d...|I should have hee...|              0|                     17|     1|\n",
            "| Whoa vanity sizing!|I was extremely e...|              0|                      2|     1|\n",
            "|            Love it!|Saw this in the s...|              1|                      0|     5|\n",
            "|Great black turtl...|I love this black...|              1|                      0|     5|\n",
            "|Elegance and comfort|I love this tunic...|              1|                      0|     5|\n",
            "|        Great skirt!|This is a throw i...|              1|                      0|     5|\n",
            "|          Great feel|   Order a size down|              1|                      2|     4|\n",
            "|A little disappoi...|I was really look...|              1|                      0|     3|\n",
            "|A basic for my cl...|Love this skirt. ...|              1|                      0|     5|\n",
            "|It won't fit over...|I saw this dress ...|              0|                      0|     1|\n",
            "|          Great top!|Love it to layer....|              1|                      0|     5|\n",
            "|Perfect dress for...|I needed a pink d...|              1|                      3|     5|\n",
            "+--------------------+--------------------+---------------+-----------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data_processed.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "former-ecology",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "former-ecology",
        "outputId": "c3dd203a-cf3d-460b-b501-6146d85159cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------------+-----------------+-----------+--------------------+----------------------------+\n",
            "|Rating| avg(Clothing ID)|         avg(Age)|avg(Rating)|avg(Recommended IND)|avg(Positive Feedback Count)|\n",
            "+------+-----------------+-----------------+-----------+--------------------+----------------------------+\n",
            "|     5|913.9147978642258|43.58657513348589|        5.0|   0.998093058733791|           2.303432494279176|\n",
            "|     1|916.0202140309156|43.70868014268728|        1.0|0.019024970273483946|          3.4625445897740783|\n",
            "|     3|928.0585365853658|42.15470383275262|        3.0|  0.4142857142857143|          3.1414634146341465|\n",
            "|     2|925.0095907928388|42.62723785166241|        2.0| 0.06010230179028133|          3.3222506393861893|\n",
            "|     4|921.4336945812807|42.88453201970443|        4.0|  0.9668965517241379|          2.4061083743842366|\n",
            "+------+-----------------+-----------------+-----------+--------------------+----------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Pretty Clear Diference\n",
        "data.groupby('Rating').mean().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "alive-london",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alive-london",
        "outputId": "287c8119-b3a5-4c07-9523-cb1473ea0c0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|Rating|count|\n",
            "+------+-----+\n",
            "|     5|13110|\n",
            "|     1|  841|\n",
            "|     3| 2870|\n",
            "|     2| 1564|\n",
            "|     4| 5075|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data_processed.groupby('Rating').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "charitable-pizza",
      "metadata": {
        "id": "charitable-pizza"
      },
      "outputs": [],
      "source": [
        "data_processed = data_processed.withColumn('label', col('Rating')-lit(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "annual-sterling",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "annual-sterling",
        "outputId": "80070223-fc3b-44b8-8ddc-8418b7c93aa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+---------------+-----------------------+------+-----+\n",
            "|               Title|         Review Text|Recommended IND|Positive Feedback Count|Rating|label|\n",
            "+--------------------+--------------------+---------------+-----------------------+------+-----+\n",
            "|                 nan|                 nan|              1|                      0|     5|    4|\n",
            "|No slip and total...|I just received t...|              0|                      0|     2|    1|\n",
            "|           A winner!|What a well-desig...|              1|                      6|     5|    4|\n",
            "|                 nan|This top is full ...|              1|                      1|     5|    4|\n",
            "|Darling top- runs...|I am a solid size...|              1|                      0|     4|    3|\n",
            "| Perfect work pants!|I love these pant...|              1|                      0|     5|    4|\n",
            "|Looks cute - but ...|This jacket looke...|              0|                      4|     2|    1|\n",
            "|    Great fall dress|I tried this dres...|              1|                      0|     5|    4|\n",
            "|Do not buy this d...|I should have hee...|              0|                     17|     1|    0|\n",
            "| Whoa vanity sizing!|I was extremely e...|              0|                      2|     1|    0|\n",
            "|            Love it!|Saw this in the s...|              1|                      0|     5|    4|\n",
            "|Great black turtl...|I love this black...|              1|                      0|     5|    4|\n",
            "|Elegance and comfort|I love this tunic...|              1|                      0|     5|    4|\n",
            "|        Great skirt!|This is a throw i...|              1|                      0|     5|    4|\n",
            "|          Great feel|   Order a size down|              1|                      2|     4|    3|\n",
            "|A little disappoi...|I was really look...|              1|                      0|     3|    2|\n",
            "|A basic for my cl...|Love this skirt. ...|              1|                      0|     5|    4|\n",
            "|It won't fit over...|I saw this dress ...|              0|                      0|     1|    0|\n",
            "|          Great top!|Love it to layer....|              1|                      0|     5|    4|\n",
            "|Perfect dress for...|I needed a pink d...|              1|                      3|     5|    4|\n",
            "+--------------------+--------------------+---------------+-----------------------+------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data_processed.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "catholic-youth",
      "metadata": {
        "id": "catholic-youth"
      },
      "source": [
        "# Feature Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "rolled-journey",
      "metadata": {
        "id": "rolled-journey"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
        "from pyspark.ml.feature import CountVectorizer, IDF, StringIndexer\n",
        "\n",
        "#rating_to_num = StringIndexer(inputCol = 'Rating', outputCol='label')\n",
        "\n",
        "tokenizer_Title = Tokenizer(inputCol='Title', outputCol='token_Title')\n",
        "stopremove_Title = StopWordsRemover(inputCol='token_Title', outputCol='stop_tokens_Title')\n",
        "count_vec_Title = CountVectorizer(inputCol='stop_tokens_Title', outputCol='c_vec_Title')\n",
        "idf_Title = IDF(inputCol='c_vec_Title', outputCol='tf_idf_Title')\n",
        "\n",
        "tokenizer_review = Tokenizer(inputCol='Review Text', outputCol='token_text')\n",
        "stopremove_review = StopWordsRemover(inputCol='token_text', outputCol='stop_tokens_text')\n",
        "count_vec_review = CountVectorizer(inputCol='stop_tokens_text', outputCol='c_vec_text')\n",
        "idf_review = IDF(inputCol='c_vec_text', outputCol='tf_idf_text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "asian-updating",
      "metadata": {
        "id": "asian-updating"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "included-klein",
      "metadata": {
        "id": "included-klein"
      },
      "outputs": [],
      "source": [
        "clean_up = VectorAssembler(inputCols=['tf_idf_Title', 'tf_idf_text', 'Recommended IND', 'Positive Feedback Count'],\n",
        "                           outputCol='features')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "advisory-edition",
      "metadata": {
        "id": "advisory-edition"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conscious-alert",
      "metadata": {
        "id": "conscious-alert"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "moderate-oliver",
      "metadata": {
        "id": "moderate-oliver"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import NaiveBayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "attended-label",
      "metadata": {
        "id": "attended-label"
      },
      "outputs": [],
      "source": [
        "nb = NaiveBayes()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "thick-excuse",
      "metadata": {
        "id": "thick-excuse"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "driven-seller",
      "metadata": {
        "id": "driven-seller"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "failing-dover",
      "metadata": {
        "id": "failing-dover"
      },
      "outputs": [],
      "source": [
        "lg = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "revised-legend",
      "metadata": {
        "id": "revised-legend"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "bottom-causing",
      "metadata": {
        "id": "bottom-causing"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "rf = RandomForestClassifier(labelCol=\"label\",\n",
        "                         featuresCol=\"features\",\n",
        "                         numTrees = 500,\n",
        "                         maxDepth = 5,\n",
        "                         maxBins = 64)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "contained-closing",
      "metadata": {
        "id": "contained-closing"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "determined-identifier",
      "metadata": {
        "id": "determined-identifier"
      },
      "outputs": [],
      "source": [
        "# Import the Decision Tree Classifier class\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "# Create a classifier object and fit to the training data\n",
        "tree = DecisionTreeClassifier(featuresCol='features',\n",
        "                             labelCol='label',\n",
        "                              predictionCol='prediction'\n",
        "                             )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "unknown-government",
      "metadata": {
        "id": "unknown-government"
      },
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "affiliated-bonus",
      "metadata": {
        "id": "affiliated-bonus"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "convertible-bobby",
      "metadata": {
        "id": "convertible-bobby"
      },
      "outputs": [],
      "source": [
        "data_prep_pipe = Pipeline(stages = [\n",
        "                                    tokenizer_Title,\n",
        "                                    tokenizer_review,\n",
        "                                    stopremove_Title,\n",
        "                                    stopremove_review,\n",
        "                                    count_vec_Title,\n",
        "                                    count_vec_review,\n",
        "                                    idf_Title,\n",
        "                                    idf_review,\n",
        "                                    clean_up])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "fatty-miniature",
      "metadata": {
        "id": "fatty-miniature"
      },
      "outputs": [],
      "source": [
        "cleaner = data_prep_pipe.fit(data_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "tested-fisher",
      "metadata": {
        "id": "tested-fisher"
      },
      "outputs": [],
      "source": [
        "clean_data = cleaner.transform(data_processed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "departmental-carpet",
      "metadata": {
        "id": "departmental-carpet"
      },
      "source": [
        "## Training and Evaluation!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "handy-canadian",
      "metadata": {
        "id": "handy-canadian"
      },
      "outputs": [],
      "source": [
        "clean_data = clean_data.select(['label', 'features'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "alleged-consortium",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alleged-consortium",
        "outputId": "3fa094a8-2540-4b3a-a62e-66efa29d9931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|    4|(43462,[0,6043,43...|\n",
            "|    1|(43462,[4,150,349...|\n",
            "|    4|(43462,[745,5923,...|\n",
            "|    4|(43462,[0,5918,59...|\n",
            "|    3|(43462,[10,33,215...|\n",
            "|    4|(43462,[7,53,138,...|\n",
            "|    1|(43462,[3,45,86,1...|\n",
            "|    4|(43462,[1,4,35,59...|\n",
            "|    0|(43462,[4,121,591...|\n",
            "|    0|(43462,[1587,2138...|\n",
            "+-----+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clean_data.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "nuclear-feeding",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuclear-feeding",
        "outputId": "45feb99d-a719-42cd-fba9-90893f05fdfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|    4|(43462,[0,6043,43...|\n",
            "|    1|(43462,[4,150,349...|\n",
            "|    4|(43462,[745,5923,...|\n",
            "|    4|(43462,[0,5918,59...|\n",
            "|    3|(43462,[10,33,215...|\n",
            "|    4|(43462,[7,53,138,...|\n",
            "|    1|(43462,[3,45,86,1...|\n",
            "|    4|(43462,[1,4,35,59...|\n",
            "|    0|(43462,[4,121,591...|\n",
            "|    0|(43462,[1587,2138...|\n",
            "+-----+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clean_data.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "meaningful-symbol",
      "metadata": {
        "id": "meaningful-symbol"
      },
      "outputs": [],
      "source": [
        "(training, testing) = clean_data.randomSplit([0.7, 0.3])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nominated-mississippi",
      "metadata": {
        "id": "nominated-mississippi"
      },
      "source": [
        "## resample data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "transsexual-hopkins",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "transsexual-hopkins",
        "outputId": "2787b40a-4052-41f5-a3d5-ba618104bdcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|    0|  585|\n",
            "|    1| 1080|\n",
            "|    3| 3547|\n",
            "|    2| 2006|\n",
            "|    4| 9091|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training.groupby('label').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "removed-acrylic",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "removed-acrylic",
        "outputId": "57d78d1e-74b2-4039-c8b3-a5e3fbf9ed7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- label: long (nullable = true)\n",
            " |-- features: vector (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mechanical-thousand",
      "metadata": {
        "id": "mechanical-thousand"
      },
      "source": [
        "=> Need to resample data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "charitable-pepper",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "charitable-pepper",
        "outputId": "45e91245-384d-4895-e758-da60781efdb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ratio df_4/df_0: 15\n",
            "ratio df_4/df_1: 8\n",
            "ratio df_4/df_2: 4\n",
            "ratio df_4/df_3: 2\n"
          ]
        }
      ],
      "source": [
        "df_0 = training.filter(col(\"label\") == 0)\n",
        "df_1 = training.filter(col(\"label\") == 1)\n",
        "df_2 = training.filter(col(\"label\") == 2)\n",
        "df_3 = training.filter(col(\"label\") == 3)\n",
        "df_4 = training.filter(col(\"label\") == 4)\n",
        "ratio_0 = int(df_4.count() / df_0.count())\n",
        "ratio_1 = int(df_4.count() / df_1.count())\n",
        "ratio_2 = int(df_4.count() / df_2.count())\n",
        "ratio_3 = int(df_4.count() / df_3.count())\n",
        "\n",
        "print(\"ratio df_4/df_0: {}\" .format(ratio_0))\n",
        "print(\"ratio df_4/df_1: {}\" .format(ratio_1))\n",
        "print(\"ratio df_4/df_2: {}\" .format(ratio_2))\n",
        "print(\"ratio df_4/df_3: {}\" .format(ratio_3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "hungarian-england",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hungarian-england",
        "outputId": "9ceccc16-b884-49e9-8289-2be247336303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|    4|(43462,[0,5911,59...|\n",
            "|    4|(43462,[0,5918,59...|\n",
            "|    4|(43462,[0,6043,43...|\n",
            "|    4|(43462,[1,4,35,59...|\n",
            "|    4|(43462,[1,9,5912,...|\n",
            "|    4|(43462,[1,12,104,...|\n",
            "|    4|(43462,[1,17,88,6...|\n",
            "|    4|(43462,[1,126,656...|\n",
            "|    4|(43462,[1,175,591...|\n",
            "|    4|(43462,[1,196,591...|\n",
            "+-----+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# resample df_0\n",
        "a0 = range(ratio_0)\n",
        "# duplicate the minority rows\n",
        "oversampled_df_0 = df_0.withColumn( \"dummy\", explode(array([lit(x) for x in a0]))).drop( 'dummy' )\n",
        "# combine both oversampled minority rows and previous majority rows\n",
        "combined_df = df_4.unionAll(oversampled_df_0)\n",
        "combined_df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "actual-primary",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "actual-primary",
        "outputId": "ed5f021c-2193-4ce6-f68d-7fa1fc70d4f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|    0| 8775|\n",
            "|    4| 9091|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "combined_df.groupBy(\"label\").count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "eligible-brisbane",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eligible-brisbane",
        "outputId": "3181ff55-1d7c-425e-8971-f34e1f0361b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|    4|(43462,[0,5911,59...|\n",
            "|    4|(43462,[0,5918,59...|\n",
            "|    4|(43462,[0,6043,43...|\n",
            "|    4|(43462,[1,4,35,59...|\n",
            "|    4|(43462,[1,9,5912,...|\n",
            "|    4|(43462,[1,12,104,...|\n",
            "|    4|(43462,[1,17,88,6...|\n",
            "|    4|(43462,[1,126,656...|\n",
            "|    4|(43462,[1,175,591...|\n",
            "|    4|(43462,[1,196,591...|\n",
            "+-----+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# resample df_1\n",
        "a1 = range(ratio_1)\n",
        "# duplicate the minority rows\n",
        "oversampled_df_1 = df_1.withColumn( \"dummy\", explode(array([lit(x) for x in a1]))).drop( 'dummy' )\n",
        "# combine both oversampled minority rows and previous majority rows\n",
        "combined_df = combined_df.unionAll(oversampled_df_1)\n",
        "combined_df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "religious-truck",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "religious-truck",
        "outputId": "ae3562b4-de43-497f-d3de-0305cd34a85a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|    0| 8775|\n",
            "|    1| 8640|\n",
            "|    4| 9091|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "combined_df.groupBy(\"label\").count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "boxed-mortgage",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boxed-mortgage",
        "outputId": "6e982ab3-cee1-49ea-844f-8a4d4784dbbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|    4|(43462,[0,5911,59...|\n",
            "|    4|(43462,[0,5918,59...|\n",
            "|    4|(43462,[0,6043,43...|\n",
            "|    4|(43462,[1,4,35,59...|\n",
            "|    4|(43462,[1,9,5912,...|\n",
            "|    4|(43462,[1,12,104,...|\n",
            "|    4|(43462,[1,17,88,6...|\n",
            "|    4|(43462,[1,126,656...|\n",
            "|    4|(43462,[1,175,591...|\n",
            "|    4|(43462,[1,196,591...|\n",
            "+-----+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# resample df_2\n",
        "a2 = range(ratio_2)\n",
        "# duplicate the minority rows\n",
        "oversampled_df_2 = df_2.withColumn( \"dummy\", explode(array([lit(x) for x in a2]))).drop( 'dummy' )\n",
        "# combine both oversampled minority rows and previous majority rows\n",
        "combined_df = combined_df.unionAll(oversampled_df_2)\n",
        "combined_df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "industrial-ozone",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "industrial-ozone",
        "outputId": "2755626e-b8a6-4682-ef07-2f604f226b38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|    0| 8775|\n",
            "|    1| 8640|\n",
            "|    2| 8024|\n",
            "|    4| 9091|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "combined_df.groupBy(\"label\").count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "confidential-investing",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "confidential-investing",
        "outputId": "fe296d49-f14a-4180-a2a8-4f65540b65ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|    4|(43462,[0,5911,59...|\n",
            "|    4|(43462,[0,5918,59...|\n",
            "|    4|(43462,[0,6043,43...|\n",
            "|    4|(43462,[1,4,35,59...|\n",
            "|    4|(43462,[1,9,5912,...|\n",
            "|    4|(43462,[1,12,104,...|\n",
            "|    4|(43462,[1,17,88,6...|\n",
            "|    4|(43462,[1,126,656...|\n",
            "|    4|(43462,[1,175,591...|\n",
            "|    4|(43462,[1,196,591...|\n",
            "+-----+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# resample df_3\n",
        "a3 = range(ratio_3)\n",
        "# duplicate the minority rows\n",
        "oversampled_df_3 = df_3.withColumn( \"dummy\", explode(array([lit(x) for x in a3]))).drop( 'dummy' )\n",
        "# combine both oversampled minority rows and previous majority rows\n",
        "combined_df = combined_df.unionAll(oversampled_df_3)\n",
        "combined_df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "resident-constitution",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "resident-constitution",
        "outputId": "de0dcbf0-fef8-46f5-f351-351dc4293971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|    0| 8775|\n",
            "|    1| 8640|\n",
            "|    3| 7094|\n",
            "|    2| 8024|\n",
            "|    4| 9091|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "combined_df.groupBy(\"label\").count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "billion-daisy",
      "metadata": {
        "id": "billion-daisy"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "imposed-beauty",
      "metadata": {
        "id": "imposed-beauty"
      },
      "outputs": [],
      "source": [
        "#rating_predictor = nb.fit(training)\n",
        "rating_predictor = nb.fit(combined_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "boring-medication",
      "metadata": {
        "id": "boring-medication"
      },
      "outputs": [],
      "source": [
        "test_results = rating_predictor.transform(testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "liberal-complexity",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liberal-complexity",
        "outputId": "836717f4-0a58-4600-e4d9-69f01034fc42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+--------------------+--------------------+----------+\n",
            "|label|            features|       rawPrediction|         probability|prediction|\n",
            "+-----+--------------------+--------------------+--------------------+----------+\n",
            "|    0|(43462,[4,121,591...|[-2174.7452628747...|[1.0,9.6225287301...|       0.0|\n",
            "|    0|(43462,[150,5763,...|[-1522.3944271800...|[4.27483438019073...|       2.0|\n",
            "|    1|(43462,[2,55,75,2...|[-1226.7503483654...|[9.38330595708897...|       2.0|\n",
            "|    1|(43462,[41,84,591...|[-824.66035147305...|[5.39869532272193...|       2.0|\n",
            "|    1|(43462,[41,517,59...|[-2365.9288810936...|[4.80153887396154...|       1.0|\n",
            "|    2|(43462,[0,5917,59...|[-1258.4198614939...|[0.99344659802346...|       0.0|\n",
            "|    2|(43462,[3,107,242...|[-1948.0193540750...|[3.07388872938400...|       2.0|\n",
            "|    2|(43462,[3,5911,59...|[-775.47364937069...|[3.30677413379999...|       4.0|\n",
            "|    2|(43462,[8,99,5912...|[-631.35714778913...|[5.66126545005195...|       3.0|\n",
            "|    2|(43462,[10,22,591...|[-988.84713416208...|[1.91622976029183...|       3.0|\n",
            "+-----+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_results.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "confirmed-summer",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "confirmed-summer",
        "outputId": "ac42c928-708c-4e36-dd9f-6180460fbf80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|    3|       0.0|   15|\n",
            "|    4|       0.0|    5|\n",
            "|    1|       3.0|  101|\n",
            "|    3|       2.0|  220|\n",
            "|    1|       0.0|   33|\n",
            "|    2|       4.0|  116|\n",
            "|    0|       1.0|   78|\n",
            "|    3|       1.0|   42|\n",
            "|    4|       4.0| 3187|\n",
            "|    0|       4.0|   27|\n",
            "|    3|       4.0|  642|\n",
            "|    4|       2.0|  133|\n",
            "|    1|       2.0|  201|\n",
            "|    4|       3.0|  671|\n",
            "|    2|       0.0|   34|\n",
            "|    2|       2.0|  305|\n",
            "|    4|       1.0|   23|\n",
            "|    3|       3.0|  609|\n",
            "|    0|       0.0|   44|\n",
            "|    1|       4.0|   42|\n",
            "+-----+----------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_results.groupBy('label', 'prediction').count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "postal-plumbing",
      "metadata": {
        "id": "postal-plumbing"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "sharing-satellite",
      "metadata": {
        "id": "sharing-satellite"
      },
      "outputs": [],
      "source": [
        "#rating_predictor2 = lg.fit(training)\n",
        "rating_predictor2 = lg.fit(combined_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "sunrise-factory",
      "metadata": {
        "id": "sunrise-factory"
      },
      "outputs": [],
      "source": [
        "test_results2 = rating_predictor2.transform(testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "placed-cleaner",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "placed-cleaner",
        "outputId": "a808b17e-7495-4634-a788-bc07edc62515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|    3|       0.0|   12|\n",
            "|    1|       3.0|   28|\n",
            "|    4|       0.0|    2|\n",
            "|    3|       2.0|  213|\n",
            "|    1|       0.0|   78|\n",
            "|    2|       4.0|  143|\n",
            "|    0|       1.0|   83|\n",
            "|    3|       1.0|   49|\n",
            "|    4|       4.0| 3514|\n",
            "|    0|       4.0|   29|\n",
            "|    3|       4.0|  809|\n",
            "|    4|       2.0|   89|\n",
            "|    1|       2.0|  160|\n",
            "|    4|       3.0|  399|\n",
            "|    2|       0.0|   74|\n",
            "|    2|       2.0|  310|\n",
            "|    4|       1.0|   15|\n",
            "|    3|       3.0|  445|\n",
            "|    0|       0.0|   85|\n",
            "|    1|       4.0|   51|\n",
            "+-----+----------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_results2.groupBy('label', 'prediction').count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rocky-newman",
      "metadata": {
        "id": "rocky-newman"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "differential-discussion",
      "metadata": {
        "id": "differential-discussion"
      },
      "outputs": [],
      "source": [
        "#rating_predictor3 = rf.fit(training)\n",
        "rating_predictor3 = rf.fit(combined_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "applicable-cannon",
      "metadata": {
        "id": "applicable-cannon"
      },
      "outputs": [],
      "source": [
        "test_results3 = rating_predictor3.transform(testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "collect-argument",
      "metadata": {
        "id": "collect-argument"
      },
      "outputs": [],
      "source": [
        "test_results3.groupBy('label', 'prediction').count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "understood-speaking",
      "metadata": {
        "id": "understood-speaking"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "lightweight-bishop",
      "metadata": {
        "id": "lightweight-bishop"
      },
      "outputs": [],
      "source": [
        "#rating_predictor4 = tree.fit(training)\n",
        "rating_predictor4 = tree.fit(combined_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "smart-drive",
      "metadata": {
        "id": "smart-drive"
      },
      "outputs": [],
      "source": [
        "test_results4 = rating_predictor4.transform(testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "worse-stevens",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "worse-stevens",
        "outputId": "47974503-83e9-492d-a049-7c15587f6e3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|    3|       0.0|   43|\n",
            "|    4|       0.0|    5|\n",
            "|    1|       3.0|    2|\n",
            "|    3|       2.0|   84|\n",
            "|    1|       0.0|  362|\n",
            "|    2|       4.0|  313|\n",
            "|    0|       1.0|   23|\n",
            "|    3|       1.0|   10|\n",
            "|    4|       4.0| 3916|\n",
            "|    0|       4.0|    7|\n",
            "|    3|       4.0| 1333|\n",
            "|    4|       2.0|   67|\n",
            "|    1|       2.0|    7|\n",
            "|    4|       3.0|   29|\n",
            "|    2|       0.0|  389|\n",
            "|    2|       2.0|   39|\n",
            "|    4|       1.0|    2|\n",
            "|    3|       3.0|   58|\n",
            "|    0|       0.0|  223|\n",
            "|    1|       4.0|   23|\n",
            "+-----+----------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_results4.groupBy('label', 'prediction').count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "heard-suicide",
      "metadata": {
        "id": "heard-suicide"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "editorial-project",
      "metadata": {
        "id": "editorial-project"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "economic-overhead",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "economic-overhead",
        "outputId": "f9687b1b-7516-4ebf-9739-c32979d2389b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of model at rating predicting was: 0.5926347632930749\n"
          ]
        }
      ],
      "source": [
        "acc_val = MulticlassClassificationEvaluator()\n",
        "acc = acc_val.evaluate(test_results)\n",
        "print('Accuracy of model at rating predicting was: {}'.format(acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "acoustic-usage",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acoustic-usage",
        "outputId": "c7dd8798-30a8-4737-9144-93c7e0725981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of model at rating predicting was: 0.6147768547398929\n"
          ]
        }
      ],
      "source": [
        "acc_val2 = MulticlassClassificationEvaluator()\n",
        "acc2 = acc_val2.evaluate(test_results2)\n",
        "print('Accuracy of model at rating predicting was: {}'.format(acc2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "super-enough",
      "metadata": {
        "id": "super-enough"
      },
      "outputs": [],
      "source": [
        "acc_val3 = MulticlassClassificationEvaluator()\n",
        "acc3 = acc_val3.evaluate(test_results3)\n",
        "print('Accuracy of model at rating predicting was: {}'.format(acc3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "spiritual-nursery",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spiritual-nursery",
        "outputId": "d7317613-6d3e-453b-c4d1-90f0eb818df5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of model at rating predicting was: 0.5115773520775087\n"
          ]
        }
      ],
      "source": [
        "acc_val4 = MulticlassClassificationEvaluator()\n",
        "acc4 = acc_val4.evaluate(test_results4)\n",
        "print('Accuracy of model at rating predicting was: {}'.format(acc4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "worth-palestine",
      "metadata": {
        "id": "worth-palestine"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "ongoing-simple",
      "metadata": {
        "id": "ongoing-simple"
      },
      "outputs": [],
      "source": [
        "pdf_new = pd.read_excel('womens-ecommerce-clothing-reviews/Womens_Clothing_E_Commerce_Reviews.xlsx', \n",
        "                               sheet_name='new_reviews', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "cross-screw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "cross-screw",
        "outputId": "e73c3d7b-29a7-4431-dbec-267dc1b5126c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c7e4b981-e6dc-44f1-9d46-25990a2e96ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clothing ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>Department Name</th>\n",
              "      <th>Class Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1077</td>\n",
              "      <td>53</td>\n",
              "      <td>Dress looks like it's made of cheap material</td>\n",
              "      <td>Dress runs small esp where the zipper area run...</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>862</td>\n",
              "      <td>66</td>\n",
              "      <td>Cute top</td>\n",
              "      <td>Nice top. armholes are a bit oversized but as ...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Knits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1080</td>\n",
              "      <td>31</td>\n",
              "      <td>Underwhelmed</td>\n",
              "      <td>Was really excited for this dress but should h...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>936</td>\n",
              "      <td>35</td>\n",
              "      <td>Absolutely perfect</td>\n",
              "      <td>If you are going for a ridiculously high price...</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Sweaters</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>872</td>\n",
              "      <td>35</td>\n",
              "      <td>Cute comfy casual</td>\n",
              "      <td>I saw this online and immediately purchased th...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Knits</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7e4b981-e6dc-44f1-9d46-25990a2e96ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c7e4b981-e6dc-44f1-9d46-25990a2e96ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c7e4b981-e6dc-44f1-9d46-25990a2e96ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Clothing ID  Age  ... Department Name Class Name\n",
              "0         1077   53  ...         Dresses    Dresses\n",
              "1          862   66  ...            Tops      Knits\n",
              "2         1080   31  ...         Dresses    Dresses\n",
              "3          936   35  ...            Tops   Sweaters\n",
              "4          872   35  ...            Tops      Knits\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "pdf_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "geographic-magnet",
      "metadata": {
        "id": "geographic-magnet"
      },
      "outputs": [],
      "source": [
        "pdf_new['Title'] = pdf['Title'].astype(str)\n",
        "pdf_new['Review Text'] = pdf['Review Text'].astype(str)\n",
        "pdf_new['Rating'] = pdf['Rating'].astype(int)\n",
        "pdf_new['Division Name'] = pdf['Division Name'].astype(str)\n",
        "pdf_new['Department Name'] = pdf['Department Name'].astype(str)\n",
        "pdf_new['Class Name'] = pdf['Class Name'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "lovely-arcade",
      "metadata": {
        "id": "lovely-arcade"
      },
      "outputs": [],
      "source": [
        "data_new = spark.createDataFrame(pdf_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "manual-burlington",
      "metadata": {
        "id": "manual-burlington"
      },
      "outputs": [],
      "source": [
        "data_processed_new = data_new.select(['Title', 'Review Text', 'Recommended IND', 'Positive Feedback Count', 'Rating'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "imperial-clause",
      "metadata": {
        "id": "imperial-clause"
      },
      "outputs": [],
      "source": [
        "data_processed_new = data_processed_new.withColumn('label', col('Rating')-lit(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "hungarian-vatican",
      "metadata": {
        "id": "hungarian-vatican"
      },
      "outputs": [],
      "source": [
        "clean_data_new = cleaner.transform(data_processed_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hispanic-taiwan",
      "metadata": {
        "id": "hispanic-taiwan"
      },
      "source": [
        "### Use logistic Regression to predict new rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "occasional-audit",
      "metadata": {
        "id": "occasional-audit"
      },
      "outputs": [],
      "source": [
        "new_results = rating_predictor2.transform(clean_data_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "comfortable-france",
      "metadata": {
        "id": "comfortable-france"
      },
      "outputs": [],
      "source": [
        "new_results = new_results.withColumn('prediction_rating', col('prediction')+lit(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "composite-accommodation",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "composite-accommodation",
        "outputId": "ea18f316-80c4-4627-c432-14f1f260f6af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|prediction_rating|\n",
            "+-----------------+\n",
            "|              5.0|\n",
            "|              5.0|\n",
            "|              3.0|\n",
            "|              5.0|\n",
            "|              5.0|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "new_results.select('prediction_rating').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caroline-comfort",
      "metadata": {
        "id": "caroline-comfort"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "colab": {
      "name": "Ex1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}